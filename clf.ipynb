{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2e27b6",
   "metadata": {},
   "source": [
    "### DEEP Assisted Tagging Tool\n",
    "\n",
    "\n",
    "In this notebook we propose an example of the main model architecture for the assisted tagging tool that will soon be implemented in [**The DEEP**](https://thedeep.io/) platform.\n",
    "\n",
    "Let's recap for completeness what The DEEP is, and how Machine Learning models improve its use. \n",
    "\n",
    "The DEEP is a collaborative platform for qualitative data analysis supporting humanitarian analytical teams to produce actionable insights. Since its inception in the aftermath of the 2015 Nepal Earthquake, DEEP has significantly contributed to improving the humanitarian data ecosystem, and today, without a doubt, is the largest repository of annotated humanitarian response documents: 50k+ sources/leads and 400k+ entries, used for 300+ projects by 3.5k+ registered users in 60+ countries.\n",
    "\n",
    "During crises, rapidly identifying important information from available data (news, reports, research, etc.) is crucial to understanding the needs of affected populations and to improving evidence-based decision-making. To make the information classification process even faster, DEEP is largely benefitting from  Natural Language Processing (NLP) and Deep Learning (DL) to aid and support the manual tagging process and give the humanitarian community more time to produce analyses and take rapid action to save more lives.\n",
    "\n",
    "Up to now, all the information (of any kind: reports, news, articles, maps, infographics, etc.) uploaded to the platform has been annotated by hand by experts in the humanitarian sector. The tagging was done under several projects according to different predefined multi-label categories (analytical frameworks). Since the data is mostly textual, we internally developed NLP models that could improve and speed up the analysis of the texts. \n",
    "\n",
    "We must also consider that informations are often contained within document reports (PDF, docx etc.) of numerous pages, making the tagging effort very difficult and time-consuming, therefore we understand how important it can be to optimize the humanitarian response during, for example, an ongoing natural disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533325ec",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's go into the details of the model now, starting from the data.\n",
    "\n",
    "In The DEEP platform each user or group has the possibility to create a project, which is usually link to a certain humanitarian crisis, such as a natural disaster, or to a certain geographic region or state where a rapid response is needed. Users can create custom labels and use them to annotate the information that will be uploaded within each project. Therefore each user will have the possibility to upload, for example, a document (of any format), select an exerpt of text (which perhaps contains important details for the purpose of the analysis) and annotate it using its own project labels. \n",
    "\n",
    "To combine entries from those projects and various analytical frameworks (set of labels), we defined a generic analytical framework and we transformed our labels accordingly. Our generic analytical framework has 10 different multi-label categories, totalling 86 different labels, covering all areas of a detailed humanitarian analysis.\n",
    "\n",
    "Our proposed dataset contains 8 categories overall:\n",
    "- 3 **primary tags**: sectors, pillars/subpillars_2d, pillars/subpillars_1d\n",
    "- 5 **secondary tags**: affected_groups, demographic_groups, specific_needs_groups, severity, geolocation\n",
    "\n",
    "Different tags are treated independently one from another. One model is trained alone for each different tag.\n",
    "\n",
    "In this notebook we focus only on a subset of above categories, **primary tags**.\n",
    "Primary tags contain 75 labels under different subcategories named as follows: \n",
    "- **Sectors** with 11 labels,\n",
    "- **2D Pillars** with  6 labels,\n",
    "- **2D Sub-pillars** with  18 labels,\n",
    "- **1D Pillars** with  7 labels,\n",
    "- **1D Sub-pillars** with  33 labels\n",
    "\n",
    "Let's see how they are divided:\n",
    "\n",
    "![image info](./img/plot.png)\n",
    "\n",
    "We can see that, apart from Sectors, each subcategory has an annotation hierarchy, from Pillar to Sub-pillar (1D and 2D) . Furthermore, each text excerpt can be annotated with multiple labels, thus making the problem a multi-label text classification.\n",
    "\n",
    "The difference between 1D and 2D Pillars (and respective Sub-pillars), as we can see in the previous image, lies in the fact that the 2D subcategory presents an additional level of hierarchy, given by the Sectors. Example:\n",
    "\n",
    "![image info](./img/ex1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import a data sample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./new_columns_train_val_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783509b6",
   "metadata": {},
   "source": [
    "Textual entries are in 3 different languages: **English**, **Spanish** and **French**.\n",
    "\n",
    "As often happens in sparse multi-label datasets, some labels are underrepresented compared to others, which may cause overfitting problems on the most numerous tags. So as a first step we have divided the 1D and 2D sub-pillars in order to build more balanced subsets of labels with which to perform separate training, and then later joining  resulting models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf8808",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The model developed is based on pre-trained transformer architecture. The transformer had to fulfill some criteria:\n",
    "- **multilingual** : it needs to work for different languages\n",
    "- **good performance** : in order for it to be useful, the model needs to be performant\n",
    "- **fast predictions** : the main goal of the modelling is to give live predictions to taggers while they are working on tagging. Speed is critical in this case and the faster the model the better.\n",
    "- **one endpoint only for deployment**: in order to optimize costs, we want to have one endpoint only for all models and predictions. To do this, we create one custom class containing models and deploy it.\n",
    "\n",
    "We use the transformer [**microsoft/xtremedistil-l6-h256-uncased**](https://huggingface.co/microsoft/xtremedistil-l6-h256-uncased) as a backbone\n",
    "\n",
    "In this notebook we overall train three independent models: one for sectors, one for subpillars (1D and 2D) and one for secondary. \n",
    "Sectors is trained with a MLP-like standard architecture.\n",
    "\n",
    "For the subpillars tags (and also for secondary tags), we use a tree-like multi-task learning model, fine-tuning the last hidden state of the transformer differently for each subtask. We have 13 different subtasks for the subpillars model (Humanitarian Conditions, At Risk, Displacement, Covid-19, Humanitarian Access, Impact, Information And Communication, Shock/Event, Capacities & Response, Context, Casualties, Priority Interventions, Priority Needs) each of which then has its own final labels, which we want to predict.\n",
    "\n",
    "Now let's get started with the serious stuff ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d78166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use pytorch and pytorch-lightning as main framweworks\n",
    "\n",
    "import torch\n",
    "import copy, os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import AdamW\n",
    "\n",
    "# importing some utilities methods\n",
    "\n",
    "from src.utils import *\n",
    "from src.loss import FocalLoss\n",
    "from src.pooling import Pooling\n",
    "from src.data import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5be607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the classifier architecture\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        ids_each_level,\n",
    "        dropout_rate=0.3,\n",
    "        output_length=384,\n",
    "        dim_hidden_layer: int = 256,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ids_each_level = ids_each_level\n",
    "        self.l0 = AutoModel.from_pretrained(model_name_or_path)\n",
    "        self.pool = Pooling(word_embedding_dimension=output_length, pooling_mode=\"cls\")\n",
    "\n",
    "        self.LayerNorm_backbone = torch.nn.LayerNorm(output_length)\n",
    "        self.LayerNorm_specific_hidden = torch.nn.LayerNorm(dim_hidden_layer)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.specific_hidden_layer = [\n",
    "            torch.nn.Linear(output_length, dim_hidden_layer) for _ in ids_each_level\n",
    "        ]\n",
    "        self.specific_hidden_layer = torch.nn.ModuleList(self.specific_hidden_layer)\n",
    "\n",
    "        self.output_layer = [\n",
    "            torch.nn.Linear(dim_hidden_layer, len(id_one_level))\n",
    "            for id_one_level in ids_each_level\n",
    "        ]\n",
    "        self.output_layer = torch.nn.ModuleList(self.output_layer)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Multi-task forward.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        output = self.l0(\n",
    "            inputs[\"ids\"],\n",
    "            attention_mask=inputs[\"mask\"],\n",
    "        )\n",
    "        output = self.pool(\n",
    "            {\n",
    "                \"token_embeddings\": output.last_hidden_state,\n",
    "                \"attention_mask\": inputs[\"mask\"],\n",
    "            }\n",
    "        )[\"sentence_embedding\"]\n",
    "\n",
    "        last_hidden_states = [output.clone() for _ in self.ids_each_level]\n",
    "\n",
    "        heads = []\n",
    "        for i in range(len(self.ids_each_level)):\n",
    "            # specific hidden layer\n",
    "            output_tmp = F.selu(last_hidden_states[i])\n",
    "            output_tmp = self.dropout(output_tmp)\n",
    "            output_tmp = self.LayerNorm_specific_hidden(output_tmp)\n",
    "\n",
    "            # output layer\n",
    "            output_tmp = self.output_layer[i](output_tmp)\n",
    "            heads.append(output_tmp)\n",
    "\n",
    "        return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f482890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch-lightining model class\n",
    "# as loss we use a BCE focal loss (details in ./src/loss.py)\n",
    "\n",
    "class Transformer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        train_params,\n",
    "        val_params,\n",
    "        tokenizer,\n",
    "        column_name,\n",
    "        multiclass,\n",
    "        learning_rate: float = 1e-5,\n",
    "        adam_epsilon: float = 1e-7,\n",
    "        warmup_steps: int = 500,\n",
    "        weight_decay: float = 0.1,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        dropout_rate: float = 0.3,\n",
    "        max_len: int = 512,\n",
    "        output_length: int = 384,\n",
    "        training_device: str = \"cuda\",\n",
    "        keep_neg_examples: bool = False,\n",
    "        dim_hidden_layer: int = 256,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.output_length = output_length\n",
    "        self.column_name = column_name\n",
    "        self.save_hyperparameters()\n",
    "        self.targets = train_dataset[\"target\"]\n",
    "        self.tagname_to_tagid = tagname_to_id(train_dataset[\"target\"])\n",
    "        self.num_labels = len(self.tagname_to_tagid)\n",
    "        self.get_first_level_ids()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.model = Model(\n",
    "            model_name_or_path,\n",
    "            self.ids_each_level,\n",
    "            dropout_rate,\n",
    "            self.output_length,\n",
    "            dim_hidden_layer,\n",
    "        )\n",
    "        self.tokenizer = tokenizer\n",
    "        self.val_params = val_params\n",
    "\n",
    "        self.training_device = training_device\n",
    "\n",
    "        self.multiclass = multiclass\n",
    "        self.keep_neg_examples = keep_neg_examples\n",
    "\n",
    "        self.training_loader = self.get_loaders(\n",
    "            train_dataset, train_params, self.tagname_to_tagid, self.tokenizer, max_len\n",
    "        )\n",
    "        self.val_loader = self.get_loaders(\n",
    "            val_dataset, val_params, self.tagname_to_tagid, self.tokenizer, max_len\n",
    "        )\n",
    "        self.Focal_loss = FocalLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        train_loss = self.get_loss(outputs, batch[\"targets\"])\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", train_loss.item(), prog_bar=True, on_step=False, on_epoch=True\n",
    "        )\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        val_loss = self.get_loss(outputs, batch[\"targets\"])\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            val_loss,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=False,\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "    def total_steps(self) -> int:\n",
    "        \"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"\n",
    "        self.dataset_size = len(self.train_dataloader().dataset)\n",
    "        num_devices = max(1, self.hparams.gpus)\n",
    "        effective_batch_size = (\n",
    "            self.hparams.train_batch_size\n",
    "            * self.hparams.accumulate_grad_batches\n",
    "            * num_devices\n",
    "        )\n",
    "        return (self.dataset_size / effective_batch_size) * self.hparams.max_epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            eps=self.hparams.adam_epsilon,\n",
    "        )\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, \"min\", 0.5, patience=self.hparams.max_epochs // 6\n",
    "        )\n",
    "        scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.training_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader\n",
    "\n",
    "    def get_loaders(\n",
    "        self, dataset, params, tagname_to_tagid, tokenizer, max_len: int = 128\n",
    "    ):\n",
    "\n",
    "        set = CustomDataset(dataset, tagname_to_tagid, tokenizer, max_len)\n",
    "        loader = DataLoader(set, **params, pin_memory=True)\n",
    "        return loader\n",
    "\n",
    "    def get_loss(self, outputs, targets, only_pos: bool = False):\n",
    "\n",
    "        # keep the if because we want to take negative examples into account for the models that contain\n",
    "        # no hierarchy (upper level models)\n",
    "        \n",
    "        if len(self.ids_each_level) == 1:\n",
    "            return self.Focal_loss(outputs[0], targets)\n",
    "        else:\n",
    "            tot_loss = 0\n",
    "            for i_th_level in range(len(self.ids_each_level)):\n",
    "                ids_one_level = self.ids_each_level[i_th_level]\n",
    "                outputs_i_th_level = outputs[i_th_level]\n",
    "                targets_one_level = targets[:, ids_one_level]\n",
    "                \n",
    "                # main objective: for each level, if row contains only zeros, not to do backpropagation\n",
    "\n",
    "                if only_pos:\n",
    "                    mask_ids_neg_example = [\n",
    "                        not bool(int(torch.sum(one_row)))\n",
    "                        for one_row in targets_one_level\n",
    "                    ]\n",
    "                    outputs_i_th_level[mask_ids_neg_example, :] = 1e-8\n",
    "\n",
    "                tot_loss += self.Focal_loss(outputs_i_th_level, targets_one_level)\n",
    "\n",
    "            return tot_loss\n",
    "\n",
    "    def get_first_level_ids(self):\n",
    "        \n",
    "        all_names = list(self.tagname_to_tagid.keys())\n",
    "        if np.all([\"->\" in name for name in all_names]):\n",
    "            first_level_names = list(\n",
    "                np.unique([name.split(\"->\")[0] for name in all_names])\n",
    "            )\n",
    "            self.ids_each_level = [\n",
    "                [i for i in range(len(all_names)) if name in all_names[i]]\n",
    "                for name in first_level_names\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            self.ids_each_level = [[i for i in range(len(all_names))]]\n",
    "\n",
    "    def custom_predict(\n",
    "        self, validation_dataset, testing=False, hypertuning_threshold: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        1) get raw predictions\n",
    "        2) postprocess them to output an output compatible with what we want in the inference\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        if testing:\n",
    "            self.val_params[\"num_workers\"] = 0\n",
    "\n",
    "        validation_loader = self.get_loaders(\n",
    "            validation_dataset,\n",
    "            self.val_params,\n",
    "            self.tagname_to_tagid,\n",
    "            self.tokenizer,\n",
    "            self.max_len,\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            testing_device = \"cuda\"\n",
    "        else:\n",
    "            testing_device = \"cpu\"\n",
    "\n",
    "        self.to(testing_device)\n",
    "        self.eval()\n",
    "        self.freeze()\n",
    "        y_true = []\n",
    "        logit_predictions = []\n",
    "        indexes = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(\n",
    "                validation_loader,\n",
    "                total=len(validation_loader.dataset) // validation_loader.batch_size,\n",
    "            ):\n",
    "\n",
    "                if not testing:\n",
    "                    y_true.append(batch[\"targets\"].detach())\n",
    "                    indexes.append(batch[\"entry_id\"].detach())\n",
    "\n",
    "                logits = self(\n",
    "                    {\n",
    "                        \"ids\": batch[\"ids\"].to(testing_device),\n",
    "                        \"mask\": batch[\"mask\"].to(testing_device),\n",
    "                        \"token_type_ids\": batch[\"token_type_ids\"].to(testing_device),\n",
    "                    }\n",
    "                )\n",
    "                logits = torch.cat(logits, dim=1)  # have a matrix like in the beginning\n",
    "                logits_to_array = np.array([np.array(t) for t in logits.cpu()])\n",
    "                logit_predictions.append(logits_to_array)\n",
    "\n",
    "        logit_predictions = np.concatenate(logit_predictions)\n",
    "        logit_predictions = sigmoid(logit_predictions)\n",
    "\n",
    "        target_list = list(self.tagname_to_tagid.keys())\n",
    "        probabilities_dict = []\n",
    "        # postprocess predictions\n",
    "        for i in range(logit_predictions.shape[0]):\n",
    "\n",
    "            # Return predictions\n",
    "            # row_pred = np.array([0] * self.num_labels)\n",
    "            row_logits = logit_predictions[i, :]\n",
    "\n",
    "            # Return probabilities\n",
    "            probabilities_item_dict = {}\n",
    "            for j in range(logit_predictions.shape[1]):\n",
    "                if hypertuning_threshold:\n",
    "                    probabilities_item_dict[target_list[j]] = row_logits[j]\n",
    "                else:\n",
    "                    probabilities_item_dict[target_list[j]] = (\n",
    "                        row_logits[j] / self.optimal_thresholds[target_list[j]]\n",
    "                    )\n",
    "\n",
    "            probabilities_dict.append(probabilities_item_dict)\n",
    "\n",
    "        if not testing:\n",
    "            y_true = np.concatenate(y_true)\n",
    "            indexes = np.concatenate(indexes)\n",
    "            return indexes, logit_predictions, y_true, probabilities_dict\n",
    "\n",
    "        else:\n",
    "            return probabilities_dict\n",
    "\n",
    "    def hypertune_threshold(self, beta_f1: float = 0.8):\n",
    "        \"\"\"\n",
    "        having the probabilities, loop over a list of thresholds to see which one:\n",
    "        1) yields the best results\n",
    "        2) without being an aberrant value\n",
    "        \"\"\"\n",
    "\n",
    "        data_for_threshold_tuning = self.val_loader.dataset.data\n",
    "        indexes, logit_predictions, y_true, _ = self.custom_predict(\n",
    "            data_for_threshold_tuning, hypertuning_threshold=True\n",
    "        )\n",
    "\n",
    "        thresholds_list = np.linspace(0.0, 1.0, 101)[::-1]\n",
    "        optimal_thresholds_dict = {}\n",
    "        optimal_scores = []\n",
    "        for ids_one_level in self.ids_each_level:\n",
    "            y_true_one_level = y_true[:, ids_one_level]\n",
    "            logit_preds_one_level = logit_predictions[:, ids_one_level]\n",
    "\n",
    "            \"\"\"if len(self.ids_each_level) > 1: #multitask\n",
    "\n",
    "                mask_at_least_one_pos = [bool(sum(row)) for row in y_true_one_level]\n",
    "                threshold_tuning_gt = y_true_one_level[mask_at_least_one_pos]\n",
    "                threshold_tuning_logit_preds = logit_preds_one_level[mask_at_least_one_pos]\n",
    "            else: #no multitask\n",
    "                threshold_tuning_gt = y_true_one_level\n",
    "                threshold_tuning_logit_preds = logit_predictions\n",
    "\n",
    "            assert(threshold_tuning_logit_preds.shape == threshold_tuning_gt.shape)\"\"\"\n",
    "\n",
    "            for j in range(len(ids_one_level)):\n",
    "                scores = []\n",
    "                for thresh_tmp in thresholds_list:\n",
    "                    metric = self.get_metric(\n",
    "                        logit_preds_one_level,\n",
    "                        y_true_one_level,\n",
    "                        beta_f1,\n",
    "                        j,\n",
    "                        thresh_tmp,\n",
    "                    )\n",
    "                    scores.append(metric)\n",
    "\n",
    "                max_threshold = 0\n",
    "                max_score = 0\n",
    "                for i in range(1, len(scores) - 1):\n",
    "                    score = np.mean(scores[i - 1 : i + 2])\n",
    "                    if score >= max_score:\n",
    "                        max_score = score\n",
    "                        max_threshold = thresholds_list[i]\n",
    "\n",
    "                optimal_scores.append(max_score)\n",
    "\n",
    "                optimal_thresholds_dict[\n",
    "                    list(self.tagname_to_tagid.keys())[ids_one_level[j]]\n",
    "                ] = max_threshold\n",
    "\n",
    "        self.optimal_thresholds = optimal_thresholds_dict\n",
    "\n",
    "        return np.mean(optimal_scores)\n",
    "\n",
    "    def get_metric(self, preds, groundtruth, beta_f1, column_idx, threshold_tmp):\n",
    "        columns_logits = np.array(preds[:, column_idx])\n",
    "\n",
    "        column_pred = [\n",
    "            1 if one_logit > threshold_tmp else 0 for one_logit in columns_logits\n",
    "        ]\n",
    "\n",
    "        if self.multiclass:\n",
    "            metric = metrics.fbeta_score(\n",
    "                groundtruth[:, column_idx],\n",
    "                column_pred,\n",
    "                beta_f1,\n",
    "                average=\"macro\",\n",
    "            )\n",
    "        else:\n",
    "            metric = metrics.f1_score(\n",
    "                groundtruth[:, column_idx],\n",
    "                column_pred,\n",
    "                average=\"macro\",\n",
    "            )\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class used to train model\n",
    "    \n",
    "class CustomTrainer:\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        training_column,\n",
    "        MODEL_DIR: str,\n",
    "        MODEL_NAME: str,\n",
    "        TOKENIZER_NAME: str,\n",
    "        dropout_rate: float,\n",
    "        train_params,\n",
    "        val_params,\n",
    "        gpu_nb: int,\n",
    "        MAX_EPOCHS: int,\n",
    "        weight_decay=0.02,\n",
    "        warmup_steps=500,\n",
    "        output_length=384,\n",
    "        max_len=150,\n",
    "        multiclass_bool=True,\n",
    "        keep_neg_examples_bool=False,\n",
    "        learning_rate=3e-5,\n",
    "        weighted_loss: str = \"sqrt\",\n",
    "        training_device: str = \"cuda\",\n",
    "        beta_f1: float = 0.8,\n",
    "        dim_hidden_layer: int = 256\n",
    "    ) -> None:\n",
    "        \n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.training_column = training_column\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.MODEL_NAME = MODEL_NAME\n",
    "        self.TOKENIZER_NAME = TOKENIZER_NAME\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.train_params = train_params\n",
    "        self.val_params = val_params\n",
    "        self.gpu_nb = gpu_nb\n",
    "        self.MAX_EPOCHS = MAX_EPOCHS\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.output_length = output_length\n",
    "        self.max_len = max_len\n",
    "        self.multiclass_bool = multiclass_bool\n",
    "        self.keep_neg_examples_bool = keep_neg_examples_bool\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weighted_loss = weighted_loss\n",
    "        self.training_device = training_device\n",
    "        self.beta_f1 = beta_f1\n",
    "        self.dim_hidden_layer = dim_hidden_layer\n",
    "\n",
    "    def train_model(self):\n",
    "        PATH_NAME = self.MODEL_DIR\n",
    "        if not os.path.exists(PATH_NAME):\n",
    "            os.makedirs(PATH_NAME)\n",
    "\n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=2, mode=\"min\"\n",
    "        )\n",
    "\n",
    "        checkpoint_callback_params = {\n",
    "            \"save_top_k\": 1,\n",
    "            \"verbose\": True,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"mode\": \"min\",\n",
    "        }\n",
    "\n",
    "        FILENAME = \"model_\" + self.training_column\n",
    "        dirpath_pillars = str(PATH_NAME)\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=dirpath_pillars, filename=FILENAME, **checkpoint_callback_params\n",
    "        )\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=FILENAME)\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            progress_bar_refresh_rate=40,\n",
    "            profiler=\"simple\",\n",
    "            log_gpu_memory=True,\n",
    "            weights_summary=None,\n",
    "            gpus=self.gpu_nb,\n",
    "            precision=16,\n",
    "            accumulate_grad_batches=1,\n",
    "            max_epochs=self.MAX_EPOCHS,\n",
    "            gradient_clip_val=1,\n",
    "            gradient_clip_algorithm=\"norm\"\n",
    "        )\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.TOKENIZER_NAME)\n",
    "        \n",
    "        model = Transformer(\n",
    "            model_name_or_path=self.MODEL_NAME,\n",
    "            train_dataset=self.train_dataset,\n",
    "            val_dataset=self.val_dataset,\n",
    "            train_params=self.train_params,\n",
    "            val_params=self.val_params,\n",
    "            tokenizer=tokenizer,\n",
    "            column_name=self.training_column,\n",
    "            gpus=self.gpu_nb,\n",
    "            plugin=\"deepspeed_stage_3_offload\",\n",
    "            accumulate_grad_batches=1,\n",
    "            max_epochs=self.MAX_EPOCHS,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            weight_decay=self.weight_decay,\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            output_length=self.output_length,\n",
    "            learning_rate=self.learning_rate,\n",
    "            multiclass=self.multiclass_bool,\n",
    "            weighted_loss=self.weighted_loss,\n",
    "            training_device=self.training_device,\n",
    "            keep_neg_examples=self.keep_neg_examples_bool,\n",
    "            dim_hidden_layer=self.dim_hidden_layer\n",
    "        )\n",
    "\n",
    "        \"\"\"lr_finder = trainer.tuner.lr_find(model)\n",
    "        new_lr = lr_finder.suggestion()\n",
    "        model.hparams.learning_rate = new_lr\"\"\"\n",
    "        trainer.fit(model)\n",
    "        model.train_f1_score = model.hypertune_threshold(self.beta_f1)\n",
    "\n",
    "        del model.training_loader\n",
    "        del model.val_loader\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12587c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = preprocess_df(dataset, column_name=\"subpillars_2d_part1\", multiclass_bool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d42205",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "MODEL_DIR = \"./models\"\n",
    "tokenizer_name = \"microsoft/xtremedistil-l6-h256-uncased\"\n",
    "model_name = \"microsoft/xtremedistil-l6-h256-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "val_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(train_dataset=train_data,\n",
    "        val_dataset=val_data,\n",
    "        training_column=\"subpillars_2d_part1\",\n",
    "        MODEL_DIR=MODEL_DIR,\n",
    "        MODEL_NAME= model_name,\n",
    "        TOKENIZER_NAME=tokenizer_name,\n",
    "        dropout_rate=0.3,\n",
    "        train_params=train_params,\n",
    "        val_params=val_params,\n",
    "        gpu_nb=1,\n",
    "        MAX_EPOCHS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f49dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad825e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5377e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_m = Transformer.load_from_checkpoint(\"/home/ec2-user/SageMaker/models/model_pillars_2d.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295d15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_m.hypertune_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa85c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = c_m.custom_predict(test, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_m.optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16911b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_final = []\n",
    "for entry_nb in range (test.shape[0]):\n",
    "    preds_column = res[entry_nb]\n",
    "    preds_entry = [\n",
    "        sub_tag for sub_tag in list(preds_column.keys()) if preds_column[sub_tag]>1\n",
    "    ]\n",
    "    preds_final.append(preds_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3973642",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = MultiLabelBinarizer()\n",
    "multi.fit(test.target)\n",
    "labels = multi.transform(test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656465c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ab72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./test_v0.7.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c24b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocess_df(test_data, column_name=\"subpillars_2d\", multiclass_bool=True, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7519066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83316a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = multi.transform(preds_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels,Y, target_names=list(multi.classes_), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14989b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def get_matrix (column_of_columns, tag_to_id, nb_subtags):\n",
    "    matrix = [[\n",
    "        1 if tag_to_id[i] in column else 0 for i in range (nb_subtags)\n",
    "    ] for column in column_of_columns]\n",
    "    return np.array(matrix)\n",
    "\n",
    "def assess_performance (preds, groundtruth, subtags):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        preds: List[List[str]]: list containing list of predicted tags for each entry\n",
    "        groundtruth: List[List[str]]: list containing list of true tags for each entry\n",
    "        subtags: subtags list, sorted by alphabetical order \n",
    "    OUTPUTS:\n",
    "        pd.DataFrame: rows: subtags, column: precision, recall, f1_score\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    nb_subtags = len(subtags)\n",
    "    tag_to_id = {i:subtags[i] for i in range (nb_subtags)}\n",
    "    groundtruth_col = get_matrix( groundtruth, tag_to_id, nb_subtags)\n",
    "    preds_col = get_matrix( preds, tag_to_id, nb_subtags)  \n",
    "    for j in range(groundtruth_col.shape[1]):  \n",
    "        preds_subtag = preds_col[:, j]\n",
    "        groundtruth_subtag = groundtruth_col[:, j]\n",
    "        results_subtag = {\n",
    "            'macro_precision': np.round(\n",
    "                metrics.precision_score(groundtruth_subtag, preds_subtag, average='macro'), 3\n",
    "            ),\n",
    "            'macro_recall': np.round(\n",
    "                metrics.recall_score(groundtruth_subtag, preds_subtag, average='macro'), 3\n",
    "            ),\n",
    "            'macro_f1_score': np.round(\n",
    "                metrics.f1_score(groundtruth_subtag, preds_subtag, average='macro'), 3\n",
    "            ),\n",
    "            '1_precision': np.round(\n",
    "                metrics.precision_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=1), 3\n",
    "            ),\n",
    "            '0_precision': np.round(\n",
    "                metrics.precision_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=0), 3\n",
    "            ),\n",
    "            '1_recall': np.round(\n",
    "                metrics.recall_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=1), 3\n",
    "            ),\n",
    "            '0_recall': np.round(\n",
    "                metrics.recall_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=0), 3\n",
    "            ),\n",
    "            '1_f1_score': np.round(\n",
    "                metrics.f1_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=1), 3\n",
    "            ),\n",
    "            '0_f1_score': np.round(\n",
    "                metrics.f1_score(groundtruth_subtag, preds_subtag, average='binary', pos_label=0), 3\n",
    "            ),\n",
    "            'hamming_loss': np.round(\n",
    "                metrics.hamming_loss(groundtruth_subtag, preds_subtag), 3\n",
    "            ),\n",
    "            'zero_one_loss': np.round(\n",
    "                metrics.zero_one_loss(groundtruth_subtag, preds_subtag), 3\n",
    "            )\n",
    "            \n",
    "        }\n",
    "        results_dict[subtags[j]] = results_subtag\n",
    "        \n",
    "    df_results = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    df_results.loc['mean'] = df_results.mean()\n",
    "        \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtags = sorted(list(multi.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assess_performance(preds_final, test.target.tolist(), subtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939be49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
